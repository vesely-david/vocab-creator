{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import os\n",
    "import nltk.corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '/Users/david.vesely/tmp/testH.text'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(filename, 'r') as f:\n",
    "    lines = f.readlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "tokens = []\n",
    "for line in lines:\n",
    "    tokens += word_tokenize(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(162246, 16038)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens), len(set(tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "pst = PorterStemmer()\n",
    "stemmed = [pst.stem(token) for token in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(162246, 10143)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stemmed), len(set(stemmed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lematization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer() \n",
    "lemmatized = [lemmatizer.lemmatize(token) for token in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(162246, 14492)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lemmatized), len(set(lemmatized))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Put process to pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(zip(tokens, stemmed, lemmatized), columns=['token', 'stemmed', 'lemmatized'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[</td>\n",
       "      <td>[</td>\n",
       "      <td>[</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>]</td>\n",
       "      <td>]</td>\n",
       "      <td>]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[</td>\n",
       "      <td>[</td>\n",
       "      <td>[</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>]</td>\n",
       "      <td>]</td>\n",
       "      <td>]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>English</td>\n",
       "      <td>english</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     token  stemmed lemmatized\n",
       "0        [        [          [\n",
       "1        ]        ]          ]\n",
       "2        [        [          [\n",
       "3        ]        ]          ]\n",
       "4  English  english    English"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'¹'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[4590, 0][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2014</td>\n",
       "      <td>2014</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2014</td>\n",
       "      <td>2014</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2011</td>\n",
       "      <td>2011</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>978-0-7710-3850-1</td>\n",
       "      <td>978-0-7710-3850-1</td>\n",
       "      <td>978-0-7710-3850-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>978-0-7710-3852-5</td>\n",
       "      <td>978-0-7710-3852-5</td>\n",
       "      <td>978-0-7710-3852-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162101</th>\n",
       "      <td>an23378504</td>\n",
       "      <td>an23378504</td>\n",
       "      <td>an23378504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162114</th>\n",
       "      <td>11267</td>\n",
       "      <td>11267</td>\n",
       "      <td>11267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162133</th>\n",
       "      <td>249</td>\n",
       "      <td>249</td>\n",
       "      <td>249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162158</th>\n",
       "      <td>1916</td>\n",
       "      <td>1916</td>\n",
       "      <td>1916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162213</th>\n",
       "      <td>1850s</td>\n",
       "      <td>1850</td>\n",
       "      <td>1850s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1312 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    token            stemmed         lemmatized\n",
       "8                    2014               2014               2014\n",
       "16                   2014               2014               2014\n",
       "33                   2011               2011               2011\n",
       "172     978-0-7710-3850-1  978-0-7710-3850-1  978-0-7710-3850-1\n",
       "177     978-0-7710-3852-5  978-0-7710-3852-5  978-0-7710-3852-5\n",
       "...                   ...                ...                ...\n",
       "162101         an23378504         an23378504         an23378504\n",
       "162114              11267              11267              11267\n",
       "162133                249                249                249\n",
       "162158               1916               1916               1916\n",
       "162213              1850s               1850              1850s\n",
       "\n",
       "[1312 rows x 3 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df['lemmatized'].str.contains('[0-9]')) & (df['lemmatized'].apply(len) > 2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>English</td>\n",
       "      <td>english</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>translation</td>\n",
       "      <td>translat</td>\n",
       "      <td>translation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>copyright</td>\n",
       "      <td>copyright</td>\n",
       "      <td>copyright</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2014</td>\n",
       "      <td>2014</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Yuval</td>\n",
       "      <td>yuval</td>\n",
       "      <td>Yuval</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          token    stemmed   lemmatized\n",
       "4       English    english      English\n",
       "5   translation   translat  translation\n",
       "6     copyright  copyright    copyright\n",
       "8          2014       2014         2014\n",
       "10        Yuval      yuval        Yuval"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "stopwords = set(stopwords.words('english'))\n",
    "removed_stopwords = df[(~df['lemmatized'].str.lower().isin(stopwords)) & (df['lemmatized'].apply(len) > 2)]\n",
    "\n",
    "# [x for x in lemmatized if x.lower() not in stopwords and len(x) > 2]\n",
    "# removed_stopwords[:20]\n",
    "removed_stopwords.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>159454</th>\n",
       "      <td>.pdf</td>\n",
       "      <td>.pdf</td>\n",
       "      <td>.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>.–ISBN</td>\n",
       "      <td>.–isbn</td>\n",
       "      <td>.–ISBN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158423</th>\n",
       "      <td>//files.shareholder.com/downloads/RBS/626570033</td>\n",
       "      <td>//files.shareholder.com/downloads/rbs/626570033</td>\n",
       "      <td>//files.shareholder.com/downloads/RBS/626570033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161358</th>\n",
       "      <td>//news.bbc.c0.uk/2/hi/8164060.stm</td>\n",
       "      <td>//news.bbc.c0.uk/2/hi/8164060.stm</td>\n",
       "      <td>//news.bbc.c0.uk/2/hi/8164060.stm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161462</th>\n",
       "      <td>//news.bbc.co.Uk/2/hi/health/7954968.stm</td>\n",
       "      <td>//news.bbc.co.uk/2/hi/health/7954968.stm</td>\n",
       "      <td>//news.bbc.co.Uk/2/hi/health/7954968.stm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93367</th>\n",
       "      <td>£25</td>\n",
       "      <td>£25</td>\n",
       "      <td>£25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93422</th>\n",
       "      <td>£58,347</td>\n",
       "      <td>£58,347</td>\n",
       "      <td>£58,347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93402</th>\n",
       "      <td>£58,348</td>\n",
       "      <td>£58,348</td>\n",
       "      <td>£58,348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37757</th>\n",
       "      <td>Çatalhöyük</td>\n",
       "      <td>çatalhöyük</td>\n",
       "      <td>Çatalhöyük</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147087</th>\n",
       "      <td>être</td>\n",
       "      <td>être</td>\n",
       "      <td>être</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>78482 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  token  \\\n",
       "159454                                             .pdf   \n",
       "176                                              .–ISBN   \n",
       "158423  //files.shareholder.com/downloads/RBS/626570033   \n",
       "161358                //news.bbc.c0.uk/2/hi/8164060.stm   \n",
       "161462         //news.bbc.co.Uk/2/hi/health/7954968.stm   \n",
       "...                                                 ...   \n",
       "93367                                               £25   \n",
       "93422                                           £58,347   \n",
       "93402                                           £58,348   \n",
       "37757                                        Çatalhöyük   \n",
       "147087                                             être   \n",
       "\n",
       "                                                stemmed  \\\n",
       "159454                                             .pdf   \n",
       "176                                              .–isbn   \n",
       "158423  //files.shareholder.com/downloads/rbs/626570033   \n",
       "161358                //news.bbc.c0.uk/2/hi/8164060.stm   \n",
       "161462         //news.bbc.co.uk/2/hi/health/7954968.stm   \n",
       "...                                                 ...   \n",
       "93367                                               £25   \n",
       "93422                                           £58,347   \n",
       "93402                                           £58,348   \n",
       "37757                                        çatalhöyük   \n",
       "147087                                             être   \n",
       "\n",
       "                                             lemmatized  \n",
       "159454                                             .pdf  \n",
       "176                                              .–ISBN  \n",
       "158423  //files.shareholder.com/downloads/RBS/626570033  \n",
       "161358                //news.bbc.c0.uk/2/hi/8164060.stm  \n",
       "161462         //news.bbc.co.Uk/2/hi/health/7954968.stm  \n",
       "...                                                 ...  \n",
       "93367                                               £25  \n",
       "93422                                           £58,347  \n",
       "93402                                           £58,348  \n",
       "37757                                        Çatalhöyük  \n",
       "147087                                             être  \n",
       "\n",
       "[78482 rows x 3 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "removed_stopwords.sort_values('token')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized = [x.lower() for x in removed_stopwords]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frequency of tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'human': 605, 'people': 511, 'world': 403, 'one': 387, 'year': 378, 'even': 373, 'could': 339, 'would': 338, 'new': 327, 'empire': 302, ...})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.probability import FreqDist\n",
    "frequencies = FreqDist(normalized)\n",
    "frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('human', 605),\n",
       " ('people', 511),\n",
       " ('world', 403),\n",
       " ('one', 387),\n",
       " ('year', 378),\n",
       " ('even', 373),\n",
       " ('could', 339),\n",
       " ('would', 338),\n",
       " ('new', 327),\n",
       " ('empire', 302)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequencies.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dictionary_filename = '/Users/david.vesely/tmp/dictionary.csv'\n",
    "dictionary = pd.read_csv(dictionary_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary.columns = ['word', 'type', 'explanation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary['word'] = dictionary['word']\\\n",
    "    .apply(lambda x: x.replace('\"', ''))\\\n",
    "    .str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = dictionary.groupby('word')\\\n",
    "    .first()\\\n",
    "    .reset_index()\\\n",
    "    .sort_values('word')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge frequencies with dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequencies_df = pd.DataFrame(frequencies.items(), columns=['word', 'frequency'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = frequencies_df.merge(dictionary, on='word', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>frequency</th>\n",
       "      <th>type</th>\n",
       "      <th>explanation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1261</th>\n",
       "      <td>validity</td>\n",
       "      <td>1</td>\n",
       "      <td>n.</td>\n",
       "      <td>The quality or state of being valid; strength;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1686</th>\n",
       "      <td>paean</td>\n",
       "      <td>1</td>\n",
       "      <td>n.</td>\n",
       "      <td>An ancient Greek hymn in honor of Apollo as a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1680</th>\n",
       "      <td>macedonian</td>\n",
       "      <td>1</td>\n",
       "      <td>a.</td>\n",
       "      <td>Belonging, or relating, to Macedonia.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1678</th>\n",
       "      <td>unquestioned</td>\n",
       "      <td>1</td>\n",
       "      <td>a.</td>\n",
       "      <td>Not called in question; not doubted.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1672</th>\n",
       "      <td>heartless</td>\n",
       "      <td>1</td>\n",
       "      <td>a.</td>\n",
       "      <td>Without a heart.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>first</td>\n",
       "      <td>225</td>\n",
       "      <td>a.</td>\n",
       "      <td>Preceding all others of a series or kind; the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>history</td>\n",
       "      <td>266</td>\n",
       "      <td>n.</td>\n",
       "      <td>A learning or knowing by inquiry; the knowledg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>new</td>\n",
       "      <td>327</td>\n",
       "      <td>superl.</td>\n",
       "      <td>Having existed, or having been made, but a sho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>year</td>\n",
       "      <td>378</td>\n",
       "      <td>n.</td>\n",
       "      <td>The time of the apparent revolution of the sun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>human</td>\n",
       "      <td>605</td>\n",
       "      <td>a.</td>\n",
       "      <td>Belonging to man or mankind; having the qualit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2524 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              word  frequency     type  \\\n",
       "1261      validity          1       n.   \n",
       "1686         paean          1       n.   \n",
       "1680    macedonian          1       a.   \n",
       "1678  unquestioned          1       a.   \n",
       "1672     heartless          1       a.   \n",
       "...            ...        ...      ...   \n",
       "2            first        225       a.   \n",
       "16         history        266       n.   \n",
       "189            new        327  superl.   \n",
       "64            year        378       n.   \n",
       "19           human        605       a.   \n",
       "\n",
       "                                            explanation  \n",
       "1261  The quality or state of being valid; strength;...  \n",
       "1686  An ancient Greek hymn in honor of Apollo as a ...  \n",
       "1680              Belonging, or relating, to Macedonia.  \n",
       "1678               Not called in question; not doubted.  \n",
       "1672                                   Without a heart.  \n",
       "...                                                 ...  \n",
       "2     Preceding all others of a series or kind; the ...  \n",
       "16    A learning or knowing by inquiry; the knowledg...  \n",
       "189   Having existed, or having been made, but a sho...  \n",
       "64    The time of the apparent revolution of the sun...  \n",
       "19    Belonging to man or mankind; having the qualit...  \n",
       "\n",
       "[2524 rows x 4 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged.sort_values('frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_filename = '/Users/david.vesely/tmp/result_01.csv'\n",
    "merged.to_csv(result_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Vocab - Python 3.8",
   "language": "python",
   "name": "vocab38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
